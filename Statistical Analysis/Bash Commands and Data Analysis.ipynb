{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of Data Science\n",
    "## Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: Harsh Yadav\n",
    "\n",
    "Student Netid: hy1217\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Case study\n",
    "- Read [this article](http://www.nytimes.com/2012/02/19/magazine/shopping-habits.html) in the New York Times.\n",
    "- Use what we've learned in class and from the book to describe how one could set Target's problem up as a predictive modeling problem, such that they could have gotten the results that they did.  Formulate your solution as a proposed plan using our data science terminology.  Include aspects of the Data Science Workflow that you see as relevant to solving the problem.  Be precise but concise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For setting Target's problem up as a predictive modeling problem, we can consider all the factor that Andrew Pole took for building his predictive model like ethnicity, job history, the magazines you read, bankruptcy, divorce, the year you bought (or lost) your house, where you went to college, what kinds of topics you talk about online, whether you prefer certain brands of coffee, paper towels, cereal or applesauce, your political leanings, reading habits, charitable giving and the number of cars you own. If we have this amount of data, then we can move beyond targeting just the pregnant women. For example, we can target the new people who come each year to US for studies/jobs. We can get the data about them through the government, Universities they get enrolled into and Companies in which they are hired. If these people are targeted and if they get used to buying from target, then it would affect the sales a lot. Also, each year a lot of students move from one place to another when they get enrolled into Universities and if we try to contact the University dorms and start giving student discounts they the new students may get used to buying from the same place again. Also, bursting these new people with a lot of student discounts on the items which they need in the beginning like groceries, clothes, stationary, etc will help in increasing the sales.\n",
    "\n",
    "Label: pregnency registry\n",
    "Features: purchasing of certiain items\n",
    "Method: Supervised learning/ Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Exploring data in the command line\n",
    "For this part we will be using the data file located in `\"data/advertising_events.csv\"`. This file consists of records that pertain to some online advertising events on a given day. There are 4 comma separated columns in this order: `userid`, `timestamp`, `domain`, and `action`. These fields are of type `int` (continuous), `int` (continuous), `string`, and `int` (category) respectively. Answer the following questions using Linux/Unix bash commands. All questions can be answered in one line (sometimes, with pipes)! Some questions will have many possible solutions. Don't forget that in IPython notebooks you must prefix all bash commands with an exclamation point, i.e. `\"!command arguments\"`.\n",
    "\n",
    "[Hints: You can experiment with whatever you want in the notebook and then delete things to construct your answer later.  You can also use ssh to use the actual bash shell on EC2 and then just paste your answers here. Recall that once you enter the \"!\" then filename completion should work.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. How many records (lines) are in this file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wc -l advertising_events.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. How many unique users are in this file? (hint: consider the 'cut' command and use pipe operator '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cut -d',' -f1 advertising_events.csv | sort | uniq | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Rank all domains by the number of visits they received in descending order. (hint: consider the 'cut', 'uniq' and 'sort' commands and the pipe operator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "awk -F ',' '{print $3}' advertising_events.csv | sort | uniq -c | sort -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. List all records for the user with user id 37. (hint: this can be done using 'grep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "awk -F ',' '$1 ~ /^37$/' advertising_events.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Dealing with data Pythonically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You might find these packages useful. You may import any others you want!\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Load the data set `\"data/ads_dataset.tsv\"` into a Python Pandas data frame called `ads`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from timeit import Timer\n",
    "ads = pd.read_csv('C:/Users/Harsh Yadav/Downloads/ads_dataset.tsv', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Write a Python function called `getDfSummary()` that does the following:\n",
    "- Takes as input a data frame\n",
    "- For each variable in the data frame calculates the following features:\n",
    "  - `number_nan` to count the number of missing not-a-number values\n",
    "  - Ignoring missing, NA, and Null values:\n",
    "    - `number_distinct` to count the number of distinct values a variable can take on\n",
    "    - `mean`, `max`, `min`, `std` (standard deviation), and `25%`, `50%`, `75%` to correspond to the appropriate percentiles\n",
    "- All of these new features should be loaded in a new data frame. Each row of the data frame should be a variable from the input data frame, and the columns should be the new summary features.\n",
    "- Returns this new data frame containing all of the summary information\n",
    "\n",
    "Hint: The pandas `describe()` [(manual page)](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html) method returns a useful series of values that can be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDfSummary(input_data):\n",
    "    number_nan=input_data.isnull().sum()                        #NaN values\n",
    "    number_distinct=input_data.nunique(dropna=True)             #Distinct values\n",
    "    percentile25=input_data.quantile(0.25)                      #25th Percentile\n",
    "    percentile50=input_data.quantile(0.50)                      #50th Percentile          \n",
    "    percentile75=input_data.quantile(0.75)                      #75th Percentile\n",
    "    df1=pd.concat([percentile25, percentile50, percentile75, number_distinct, number_nan], axis=1)\n",
    "    df1.columns = ['25 Percentile', '50 Percentile', '75 Percentile', 'Distinct Elements', 'Number of NaN']\n",
    "    aggregate=input_data.agg([pd.np.min, pd.np.max, pd.np.mean, pd.np.std])\n",
    "    aggregate=aggregate.T\n",
    "    output_data=pd.concat([aggregate,df1], axis=1)\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. How long does it take for your `getDfSummary()` function to work on your `ads` data frame? Show us the results below.\n",
    "\n",
    "Hint: `%timeit getDfSummary(ads)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09308074754966567\n"
     ]
    }
   ],
   "source": [
    "t = Timer(lambda: getDfSummary(ads))                     #Time to execute the above function\n",
    "print (t.timeit(number=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Using the results returned from `getDfSummary()`, which fields, if any, contain missing `NaN` values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buy_freq']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4=getDfSummary(ads)\n",
    "df4.index[df4['Number of NaN']>0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. For the fields with missing values, does it look like the data is missing at random? Are there any other fields that correlate perfectly, or predict that the data is missing? What would be an appropriate method for filling in missing values?\n",
    "\n",
    "Hint: create another data frame that has just the records with a missing value. Get a summary of this data frame using `getDfSummary()` and compare the differences. Do some feature distributions change dramatically?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amin</th>\n",
       "      <th>amax</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>25 Percentile</th>\n",
       "      <th>50 Percentile</th>\n",
       "      <th>75 Percentile</th>\n",
       "      <th>Distinct Elements</th>\n",
       "      <th>Number of NaN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>isbuyer</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy_freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>52257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_freq</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>84.00000</td>\n",
       "      <td>1.651549</td>\n",
       "      <td>2.147955</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy_interval</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv_interval</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>184.91670</td>\n",
       "      <td>5.686388</td>\n",
       "      <td>17.623555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>5112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expected_time_buy</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expected_time_visit</th>\n",
       "      <td>-187.6156</td>\n",
       "      <td>91.40192</td>\n",
       "      <td>-9.669298</td>\n",
       "      <td>31.239030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_buy</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>188.00000</td>\n",
       "      <td>65.741317</td>\n",
       "      <td>53.484622</td>\n",
       "      <td>19.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_visit</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>188.00000</td>\n",
       "      <td>65.741317</td>\n",
       "      <td>53.484622</td>\n",
       "      <td>19.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple_buy</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple_visit</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.255602</td>\n",
       "      <td>0.436203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniq_urls</th>\n",
       "      <td>-1.0000</td>\n",
       "      <td>206.00000</td>\n",
       "      <td>86.656180</td>\n",
       "      <td>61.996711</td>\n",
       "      <td>30.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>207</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_checkins</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>37091.00000</td>\n",
       "      <td>721.848518</td>\n",
       "      <td>1284.504018</td>\n",
       "      <td>126.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>803.000000</td>\n",
       "      <td>4570</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_buy</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.003024</td>\n",
       "      <td>0.054904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         amin         amax        mean          std  \\\n",
       "isbuyer                0.0000      0.00000    0.000000     0.000000   \n",
       "buy_freq                  NaN          NaN         NaN          NaN   \n",
       "visit_freq             1.0000     84.00000    1.651549     2.147955   \n",
       "buy_interval           0.0000      0.00000    0.000000     0.000000   \n",
       "sv_interval            0.0000    184.91670    5.686388    17.623555   \n",
       "expected_time_buy      0.0000      0.00000    0.000000     0.000000   \n",
       "expected_time_visit -187.6156     91.40192   -9.669298    31.239030   \n",
       "last_buy               0.0000    188.00000   65.741317    53.484622   \n",
       "last_visit             0.0000    188.00000   65.741317    53.484622   \n",
       "multiple_buy           0.0000      0.00000    0.000000     0.000000   \n",
       "multiple_visit         0.0000      1.00000    0.255602     0.436203   \n",
       "uniq_urls             -1.0000    206.00000   86.656180    61.996711   \n",
       "num_checkins           1.0000  37091.00000  721.848518  1284.504018   \n",
       "y_buy                  0.0000      1.00000    0.003024     0.054904   \n",
       "\n",
       "                     25 Percentile  50 Percentile  75 Percentile  \\\n",
       "isbuyer                        0.0            0.0       0.000000   \n",
       "buy_freq                       NaN            NaN            NaN   \n",
       "visit_freq                     1.0            1.0       2.000000   \n",
       "buy_interval                   0.0            0.0       0.000000   \n",
       "sv_interval                    0.0            0.0       0.041667   \n",
       "expected_time_buy              0.0            0.0       0.000000   \n",
       "expected_time_visit            0.0            0.0       0.000000   \n",
       "last_buy                      19.0           52.0     106.000000   \n",
       "last_visit                    19.0           52.0     106.000000   \n",
       "multiple_buy                   0.0            0.0       0.000000   \n",
       "multiple_visit                 0.0            0.0       1.000000   \n",
       "uniq_urls                     30.0           75.0     155.000000   \n",
       "num_checkins                 126.0          318.0     803.000000   \n",
       "y_buy                          0.0            0.0       0.000000   \n",
       "\n",
       "                     Distinct Elements  Number of NaN  \n",
       "isbuyer                              1              0  \n",
       "buy_freq                             0          52257  \n",
       "visit_freq                          48              0  \n",
       "buy_interval                         1              0  \n",
       "sv_interval                       5112              0  \n",
       "expected_time_buy                    1              0  \n",
       "expected_time_visit              13351              0  \n",
       "last_buy                           189              0  \n",
       "last_visit                         189              0  \n",
       "multiple_buy                         1              0  \n",
       "multiple_visit                       2              0  \n",
       "uniq_urls                          207              0  \n",
       "num_checkins                      4570              0  \n",
       "y_buy                                2              0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads1=ads[ads.isnull().any(axis=1)]\n",
    "ads2=getDfSummary(ads1)\n",
    "ads2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Answer: We can see that for the variable buy_freq, all the results except Distict elements and Number of NaN are NaN. This is because there are no values for buy_freq if we discard the NaN values from our initial data frame. So, we notice that the data is missing form other columns where ever buy_freq has a value. If we look at the isbuyer variable, then we notice that whenever buy_freq has a value other than NaN, then the value of isbuyer is 1, otherwise it is 0. So, for filling the missing values, we must have the data for isbuyer column to determine the buy_freq.\n",
    "\n",
    "when multiple_buy is 0, then buy_freq is 0.\n",
    "Fill the values with 0 or mean/mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Which variables are binary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['isbuyer', 'multiple_buy', 'multiple_visit', 'y_buy']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary = [column for column in ads if ads[[column]].dropna().isin([0, 1]).all().values]\n",
    "binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
